# 整体系统介绍

搜索引擎大致可以分为四个部分：搜集、分析、索引、查询

- 搜集，就是我们常说的利用爬虫爬取网页。
- 分析，主要负责网页内容抽取、分词，构建临时索引，计算 PageRank 值这几部分工作。
- 索引，主要负责通过分析阶段得到的临时索引，构建倒排索引。
- 查询，主要负责响应用户的请求，根据倒排索引获取相关网页，计算网页排名，返回查询结果给用户。


## 搜集

搜集需要有一个 `种子` 网站开始(相当于一个 起点); 
从这个起点开始, 如果有其它的链接, 就链接放入队列中, 等待搜集;

这就像一个有向图, 我们会遍历到非常多的链接;
一般情况下, 会选择 `广度优先遍历`

> 因为涉及到的链接可能非常多, 不太适合深度优先遍历

### 爬取的网页链接

通过广度优先遍历, 可能获取到非常多的url, 内存可能放不下;
此时, 需要把url 持久化, 放入文件中; 

这样, 也可以断电之后继续爬取


### 网页判重

爬取的网页数量会非常的多, 那么如何判断网页是否已经被爬取过了呢? 
可以使用 `布隆过滤器(bloom filter)`

因为爬取过的网页会非常多, 所以也需要做持久化; 

### 原始的网页存储

为了之后的分析, 我们需要将爬取过的网页的存储起来;

如果, 每一个网页都用一个文件存储起来, 那么会有太多的文件;
文件系统, 不适合存储这么多的文件;
所以, 我们可以把多个网页存储到一个文件中;


### 网页链接及其编号对应的文件



